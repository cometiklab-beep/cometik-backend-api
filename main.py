import os
import uuid
import whisper
import json
import re 
import csv 
from datetime import datetime

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel

from sqlalchemy import create_engine, text 

# (A) CONFIGURACI√ìN LLAMA: Define la ruta del modelo GGUF (la carga est√° deshabilitada)
LLAMA_MODEL_PATH = os.path.join(os.path.dirname(__file__), "llama_model.gguf")

# --- DESCRIPCI√ìN EXTENSA DE LA API ---
API_DESCRIPTION = (
    "API para la recolecci√≥n, transcripci√≥n y an√°lisis automatizado de respuestas verbales infantiles "
    "en el marco de la validaci√≥n convergente entre el CCC-2 y COMETI-K. Esta bater√≠a cognitivo-ling√º√≠stica "
    "gamificada en Unity eval√∫a los criterios del DSM-5 para el trastorno de la comunicaci√≥n social (pragm√°tico), "
    "integrando m√©tricas discursivas para un an√°lisis ling√º√≠stico robusto."
)

# --- CONFIGURACI√ìN DE LA API ---
app = FastAPI(
    title="COMETI-K Backend Cl√≠nico y Ling√º√≠stico",
    description=API_DESCRIPTION,
    version="1.0.0"
)

# Directorio donde se guardar√°n los archivos de audio y resultados
STORAGE_DIR = "datos_clinicos" 
if not os.path.exists(STORAGE_DIR):
    os.makedirs(STORAGE_DIR)

# --- CONFIGURACI√ìN DE LA BASE DE DATOS ---
# Render inyectar√° la variable DATABASE_URL autom√°ticamente
DATABASE_URL = os.environ.get('DATABASE_URL')
DB_ENGINE = None
if DATABASE_URL:
    try:
        # Crea el motor de conexi√≥n a la base de datos
        DB_ENGINE = create_engine(DATABASE_URL)
        print("‚úÖ Motor de PostgreSQL configurado correctamente.")
    except Exception as e:
        print(f"‚ùå Error al crear el motor de PostgreSQL: {e}")

# --- MODELOS DE DATOS ---
class AnalysisRequest(BaseModel):
    """Modelo para solicitar el an√°lisis de texto por el LLM."""
    document_id: str
    pregunta_id: str
    transcription: str

class AnalysisResponse(BaseModel):
    """Modelo de la respuesta del LLM con puntuaciones cl√≠nicas y ling√º√≠sticas (0, 1, 2)."""
    # ENFOQUE DUAL: Calificaci√≥n cl√≠nica (A1-A4) y Calificaci√≥n ampliada (A1-A6)
    calificacion_pragmatica_dsm5: float  
    calificacion_pragmatica_ampliada: float
    comentario_llm: str
    
    # CRITERIOS DSM-5 PUROS (A1-A4)
    puntuacion_a1_uso_social: int
    puntuacion_a2_ajuste_contexto: int
    puntuacion_a3_normas_conversacionales: int
    puntuacion_a4_comprension_no_literal: int
    
    # CRITERIOS LING√ú√çSTICOS ADICIONALES (A5-A6)
    puntuacion_a5_coherencia: int         
    puntuacion_a6_cohesion: int           
    
    # AN√ÅLISIS DISCURSIVOS EXTRA
    analisis_complejidad_sintactica: int
    analisis_disfluencias: int

# --- CARGA DE MODELOS ---
# Carga el modelo de Whisper
try:
    WHISPER_MODEL = whisper.load_model("base")
    print("‚úÖ Modelo Whisper 'base' cargado correctamente.")
except Exception as e:
    print(f"‚ùå Error al cargar el modelo Whisper: {e}")
    WHISPER_MODEL = None

# (B) CARGA REAL DEL MODELO LLAMA - DESHABILITADA
LLAMA_MODEL = None
print("‚ö†Ô∏è Modo de An√°lisis de LLama forzado a SIMULACI√ìN para evitar Timeouts.")


# --- FUNCIONES DE SIMULACI√ìN Y AN√ÅLISIS ---

def simulate_llama_analysis(transcription: str) -> dict:
    """Funci√≥n de an√°lisis SIMULADO, con las 8 m√©tricas requeridas."""
    word_count = len(transcription.split())
    
    if word_count < 5:
        puntuaciones_dsm5 = [0, 0, 1, 0] 
        puntuaciones_discurso = [0, 1]  
        comment = "SIMULADO: Respuesta muy corta. Baja evidencia de competencia pragm√°tica."
    elif word_count < 15:
        puntuaciones_dsm5 = [1, 1, 1, 0]
        puntuaciones_discurso = [1, 1]
        comment = "SIMULADO: Respuesta coherente, pero breve. Competencia media."
    else:
        puntuaciones_dsm5 = [2, 2, 2, 1]
        puntuaciones_discurso = [2, 2]
        comment = "SIMULADO: Respuesta fluida con buena articulaci√≥n. Alta competencia pragm√°tica."
    
    # C√°lculo de promedios para simulaci√≥n
    calificacion_pragmatica_dsm5 = round(sum(puntuaciones_dsm5) / 4, 2)
    puntuaciones_totales = puntuaciones_dsm5 + puntuaciones_discurso
    calificacion_pragmatica_ampliada = round(sum(puntuaciones_totales) / 6, 2)
    
    return {
        "calificacion_pragmatica_dsm5": calificacion_pragmatica_dsm5,
        "calificacion_pragmatica_ampliada": calificacion_pragmatica_ampliada,
        "comentario_llm": comment,
        "puntuacion_a1_uso_social": puntuaciones_dsm5[0],
        "puntuacion_a2_ajuste_contexto": puntuaciones_dsm5[1],
        "puntuacion_a3_normas_conversacionales": puntuaciones_dsm5[2],
        "puntuacion_a4_comprension_no_literal": puntuaciones_dsm5[3],
        "puntuacion_a5_coherencia": puntuaciones_discurso[0],
        "puntuacion_a6_cohesion": puntuaciones_discurso[1],
        "analisis_complejidad_sintactica": 1, 
        "analisis_disfluencias": 2            
    }

def run_llama_analysis(transcription: str, pregunta_id: str) -> dict:
    """
    Funci√≥n de an√°lisis con prompt estructurado para los criterios DSM-5 y ling√º√≠sticos (0, 1, 2).
    """
    if LLAMA_MODEL is None:
        return simulate_llama_analysis(transcription)

    # --- CRITERIOS DEFINITIVOS PARA EL PROMPT (Si LLAMA estuviera activo) ---
    CRITERIOS_ANALISIS = (
        "Instrucciones de puntuaci√≥n (0=Ausencia del Criterio/D√©ficit, 1=Presencia Parcial, 2=Presencia Clara del Criterio):\n"
        "1. A1_Uso_Social (Uso del lenguaje en contextos sociales):\n"
        "2. A2_Ajuste_Contexto (Cambio del lenguaje seg√∫n contexto o interlocutor):\n"
        "3. A3_Normas_Conversacionales (Seguimiento de normas conversacionales y narrativas):\n"
        "4. A4_Comprension_No_Literal (Comprensi√≥n de inferencias, met√°foras y lenguaje no literal):\n\n"
        "5. A5_Coherencia (Nivel Discursivo - L√≥gica en el encadenamiento de ideas):\n"
        "6. A6_Cohesi√≥n (Nivel Ling√º√≠stico - Uso de conectores y referentes):\n\n"
        "7. Complejidad_Sint√°ctica (0=Baja, 1=Media, 2=Alta):\n"
        "8. Disfluencias (0=Alta Presencia, 1=Media, 2=Baja/Nula Presencia):\n"
    )
    
    SYSTEM_PROMPT = (
        "Eres un experto en el diagn√≥stico del Trastorno de la Comunicaci√≥n Social (TCS) con un enfoque pragm√°tico-ling√º√≠stico. "
        "Tu tarea es puntuar la competencia pragm√°tica y discursiva de la respuesta de un ni√±o/a (6-12 a√±os) "
        "usando la escala discreta 0, 1, 2. La Calificaci√≥n DSM-5 es el promedio de A1-A4. La Calificaci√≥n Ampliada es el promedio de A1-A6."
    )
    
    USER_PROMPT = (
        f"PREGUNTA ID: {pregunta_id}\n"
        f"TEXTO A ANALIZAR: '{transcription}'\n\n"
        f"{CRITERIOS_ANALISIS}"
        "Genera un comentario conciso (m√°x 40 palabras) y la Puntuaci√≥n Pragm√°tica Global final."
        "IMPORTANTE: Proporciona la salida en el siguiente formato EXACTO:\n"
        "Puntuaciones: A1_Uso_Social: [X], A2_Ajuste_Contexto: [X], A3_Normas_Conversacionales: [X], A4_Comprension_No_Literal: [X], A5_Coherencia: [X], A6_Cohesi√≥n: [X], Complejidad_Sint√°ctica: [X], Disfluencias: [X]\n"
        "Comentario: [Texto conciso]\n"
        "DSM5: [Puntuaci√≥n Decimal XX]\n"
        "AMPLIADA: [Puntuaci√≥n Decimal XX]\n"
    )

    prompt = f"### System: {SYSTEM_PROMPT}\n### User: {USER_PROMPT}\n### Assistant:"

    try:
        # Si LLAMA_MODEL est√° activo, se har√≠a la llamada real aqu√≠

        # --- L√ìGICA DE PARSEO Y C√ÅLCULO ---
        # (El c√≥digo de parsing se mantiene, asumiendo una respuesta estructurada o usando el fallback de simulaci√≥n)
        
        # Simulando una respuesta estructurada para fines de prueba/parsing si LLAMA_MODEL es None
        response_text = "Puntuaciones: A1_Uso_Social: [2], A2_Ajuste_Contexto: [2], A3_Normas_Conversacionales: [1], A4_Comprension_No_Literal: [0], A5_Coherencia: [2], A6_Cohesi√≥n: [1], Complejidad_Sint√°ctica: [2], Disfluencias: [2]\nComentario: Placeholder para prueba de parsing.\nDSM5: 1.25\nAMPLIADA: 1.33"

        puntuaciones_match = re.search(r"Puntuaciones:\s*(.*)", response_text)
        dsm5_score_match = re.search(r"DSM5:\s*(\d\.\d+)", response_text)
        ampliada_score_match = re.search(r"AMPLIADA:\s*(\d\.\d+)", response_text)
        comment_match = re.search(r"Comentario:\s*(.*)", response_text)

        # Extracci√≥n de puntuaciones discretas
        scores_dict = {}
        if puntuaciones_match:
            scores_str = puntuaciones_match.group(1).replace('[', '').replace(']', '')
            criterios = re.findall(r"([A-Za-z0-9_]+):\s*(\d)", scores_str)
            for key, value in criterios:
                scores_dict[key] = int(value)

        # C√°lculo de promedios
        score_keys_dsm5 = ['A1_Uso_Social', 'A2_Ajuste_Contexto', 'A3_Normas_Conversacionales', 'A4_Comprension_No_Literal']
        score_keys_ampliada = score_keys_dsm5 + ['A5_Coherencia', 'A6_Cohesi√≥n']
        
        # Fallback de puntuaciones
        dsm5_scores = [scores_dict.get(k, 0) for k in score_keys_dsm5]
        ampliada_scores = [scores_dict.get(k, 0) for k in score_keys_ampliada]

        # Puntuaci√≥n Global (DSM-5 Puro)
        calificacion_pragmatica_dsm5 = float(dsm5_score_match.group(1)) if dsm5_score_match else (sum(dsm5_scores) / len(dsm5_scores))
        
        # Puntuaci√≥n Ampliada (Ling√º√≠stico/Discursivo)
        calificacion_pragmatica_ampliada = float(ampliada_score_match.group(1)) if ampliada_score_match else (sum(ampliada_scores) / len(ampliada_scores))

        comentario_llm = comment_match.group(1).strip() if comment_match else response_text[:100]

        return {
            "calificacion_pragmatica_dsm5": round(calificacion_pragmatica_dsm5, 2),
            "calificacion_pragmatica_ampliada": round(calificacion_pragmatica_ampliada, 2),
            "comentario_llm": comentario_llm,
            "puntuacion_a1_uso_social": scores_dict.get('A1_Uso_Social', 0),
            "puntuacion_a2_ajuste_contexto": scores_dict.get('A2_Ajuste_Contexto', 0),
            "puntuacion_a3_normas_conversacionales": scores_dict.get('A3_Normas_Conversacionales', 0),
            "puntuacion_a4_comprension_no_literal": scores_dict.get('A4_Comprension_No_Literal', 0),
            "puntuacion_a5_coherencia": scores_dict.get('A5_Coherencia', 0),
            "puntuacion_a6_cohesion": scores_dict.get('A6_Cohesi√≥n', 0),
            "analisis_complejidad_sintactica": scores_dict.get('Complejidad_Sint√°ctica', 1),
            "analisis_disfluencias": scores_dict.get('Disfluencias', 1)
        }
    except Exception as e:
        print(f"‚ùå Error cr√≠tico en el LLama o Parseo: {e}. Volviendo a la simulaci√≥n.")
        return simulate_llama_analysis(transcription)

def save_to_database(analysis_data: dict, transcription: str, document_id: str):
    """Inserta una fila de datos de an√°lisis en la tabla de PostgreSQL."""
    if not DB_ENGINE:
        print("‚ö†Ô∏è No se pudo guardar en la DB: Motor no inicializado.")
        return

    # Los datos se mapean a las columnas exactas de la tabla SQL
    data = {
        'document_id': document_id,
        'timestamp': datetime.now().isoformat(),
        # 'pregunta_id' ya viene en analysis_data gracias al fix en analyze_text
        'pregunta_id': analysis_data['pregunta_id'], 
        'calificacion_pragmatica_dsm5': analysis_data['calificacion_pragmatica_dsm5'],
        'calificacion_pragmatica_ampliada': analysis_data['calificacion_pragmatica_ampliada'],
        'puntuacion_a1_uso_social': analysis_data['puntuacion_a1_uso_social'],
        'puntuacion_a2_ajuste_contexto': analysis_data['puntuacion_a2_ajuste_contexto'],
        'puntuacion_a3_normas_conversacionales': analysis_data['puntuacion_a3_normas_conversacionales'],
        'puntuacion_a4_comprension_no_literal': analysis_data['puntuacion_a4_comprension_no_literal'],
        'puntuacion_a5_coherencia': analysis_data['puntuacion_a5_coherencia'],
        'puntuacion_a6_cohesion': analysis_data['puntuacion_a6_cohesion'],
        'analisis_complejidad_sintactica': analysis_data['analisis_complejidad_sintactica'],
        'analisis_disfluencias': analysis_data['analisis_disfluencias'],
        'comentario_llm': analysis_data['comentario_llm'],
        'transcripcion_completa': transcription
    }

    # Se construyen din√°micamente las columnas y los placeholders para la inserci√≥n
    columns = ', '.join(data.keys())
    values_placeholders = ', '.join([f":{k}" for k in data.keys()])
    
    sql_insert = text(f"""
        INSERT INTO cometik_analisis ({columns})
        VALUES ({values_placeholders})
    """)
    
    try:
        with DB_ENGINE.connect() as connection:
            connection.execute(sql_insert, data)
            connection.commit()
        print(f"‚úÖ Datos de la Pregunta {data['pregunta_id']} insertados en PostgreSQL.")
    except Exception as e:
        print(f"‚ùå Error al insertar datos en PostgreSQL: {e}")

# --- ENDPOINTS ---

@app.get("/", tags=["Estado"])
def read_root():
    """Verifica si la API est√° en funcionamiento."""
    return {"status": "ok", "message": "API de COMETI-K activa y lista."}

@app.post("/upload_audio/", tags=["Audio y Transcripci√≥n"])
async def upload_audio(
    document_id: str,
    pregunta_id: str,
    audio_file: UploadFile = File(...)
):
    """
    Recibe un archivo de audio, lo guarda, lo transcribe usando Whisper, 
    y a√±ade la transcripci√≥n al archivo resumen (.txt) del participante.
    """
    
    if not WHISPER_MODEL:
        raise HTTPException(status_code=503, detail="El modelo de transcripci√≥n Whisper no est√° cargado.")

    # 1. Definici√≥n de rutas y creaci√≥n de la carpeta del participante
    file_extension = os.path.splitext(audio_file.filename)[1]
    document_folder = os.path.join(STORAGE_DIR, document_id)
    if not os.path.exists(document_folder):
        os.makedirs(document_folder)
        
    file_name = f"{pregunta_id}_{str(uuid.uuid4()).split('-')[0]}{file_extension}"
    file_path = os.path.join(document_folder, file_name)

    # 2. Guardar el archivo de audio
    try:
        with open(file_path, "wb") as buffer:
            while chunk := await audio_file.read(1024 * 1024):
                buffer.write(chunk)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error al guardar el archivo: {e}")

    # 3. Transcribir el audio usando Whisper
    try:
        result = WHISPER_MODEL.transcribe(file_path)
        transcription = result["text"].strip()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error durante la transcripci√≥n de Whisper: {e}")

    # 4. Guardar la transcripci√≥n en el archivo resumen (.txt)
    try:
        resumen_filename = f"RESUMEN_TRANSCRIPCIONES_{document_id}.txt"
        resumen_path = os.path.join(document_folder, resumen_filename)
        
        with open(resumen_path, 'a', encoding='utf-8') as f:
            f.write(f"--- PREGUNTA {pregunta_id} ---\n")
            f.write(f"Audio: {file_name}\n") 
            f.write(f"Transcripci√≥n: {transcription}\n\n")
            
    except Exception as e:
        print(f"Advertencia: No se pudo escribir en el archivo resumen (.txt). {e}")
        
    # 5. Respuesta final
    return JSONResponse(content={
        "document_id": document_id,
        "pregunta_id": pregunta_id,
        "audio_path": file_path,
        "transcription": transcription,
        "message": "Audio guardado, transcrito y a√±adido al resumen del participante."
    })

@app.post("/analyze_text/", response_model=AnalysisResponse, tags=["An√°lisis LLM"])
def analyze_text(request: AnalysisRequest):
    """
    Recibe una transcripci√≥n de texto y realiza un an√°lisis SIMULADO (o real), 
    guardando el resultado en un archivo CSV y en la base de datos PostgreSQL.
    """
    
    # 1. Realizar el an√°lisis (simulaci√≥n o real)
    analysis_data = run_llama_analysis(request.transcription, request.pregunta_id)
    
    # üåü CORRECCI√ìN CLAVE: Agregamos pregunta_id al diccionario de datos analizados.
    # Esto soluciona el KeyError al llamar a save_to_database.
    analysis_data['pregunta_id'] = request.pregunta_id
    
    document_folder = os.path.join(STORAGE_DIR, request.document_id)
    if not os.path.exists(document_folder):
        os.makedirs(document_folder)
            
    # --- 2. GUARDAR EL AN√ÅLISIS EN UN ARCHIVO CSV CONSOLIDADO (M√âTODO LOCAL) ---
    try:
        csv_filename = f"ANALISIS_RESUMEN_{request.document_id}.csv"
        csv_path = os.path.join(document_folder, csv_filename)
        
        # Define los campos del archivo CSV
        fieldnames = [
            'timestamp', 
            'pregunta_id', 
            'calificacion_pragmatica_dsm5',       
            'calificacion_pragmatica_ampliada',   
            'puntuacion_a1_uso_social', 
            'puntuacion_a2_ajuste_contexto', 
            'puntuacion_a3_normas_conversacionales', 
            'puntuacion_a4_comprension_no_literal',  
            'puntuacion_a5_coherencia', 
            'puntuacion_a6_cohesion', 
            'analisis_complejidad_sintactica', 
            'analisis_disfluencias', 
            'comentario_llm', 
            'transcripcion_completa'
        ]
        
        # Datos a escribir en la fila
        csv_data = {
            'timestamp': datetime.now().isoformat(),
            'pregunta_id': analysis_data['pregunta_id'],
            'calificacion_pragmatica_dsm5': analysis_data['calificacion_pragmatica_dsm5'],
            'calificacion_pragmatica_ampliada': analysis_data['calificacion_pragmatica_ampliada'],
            'puntuacion_a1_uso_social': analysis_data['puntuacion_a1_uso_social'],
            'puntuacion_a2_ajuste_contexto': analysis_data['puntuacion_a2_ajuste_contexto'],
            'puntuacion_a3_normas_conversacionales': analysis_data['puntuacion_a3_normas_conversacionales'],
            'puntuacion_a4_comprension_no_literal': analysis_data['puntuacion_a4_comprension_no_literal'],
            'puntuacion_a5_coherencia': analysis_data['puntuacion_a5_coherencia'],
            'puntuacion_a6_cohesion': analysis_data['puntuacion_a6_cohesion'],
            'analisis_complejidad_sintactica': analysis_data['analisis_complejidad_sintactica'],
            'analisis_disfluencias': analysis_data['analisis_disfluencias'],
            'comentario_llm': analysis_data['comentario_llm'].replace('\n', ' '), 
            'transcripcion_completa': request.transcription.replace('\n', ' ')
        }

        # Comprueba si el archivo existe para escribir el encabezado
        is_new_file = not os.path.exists(csv_path)
        
        with open(csv_path, 'a', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            if is_new_file:
                writer.writeheader() # Escribe el encabezado solo si es un archivo nuevo
            
            writer.writerow(csv_data)

    except Exception as e:
        print(f"Advertencia: No se pudo escribir en el archivo CSV de an√°lisis. {e}")
        
    # --- 3. GUARDAR EL AN√ÅLISIS EN LA BASE DE DATOS RELACIONAL ---
    save_to_database(analysis_data, request.transcription, request.document_id)
        
    # --- 4. Guardar el an√°lisis completo en un archivo JSON individual ---
    try:
        analysis_filename = f"{request.pregunta_id}_analysis_{str(uuid.uuid4()).split('-')[0]}.json"
        analysis_path = os.path.join(document_folder, analysis_filename)
        
        full_data = {
            "document_id": request.document_id,
            "pregunta_id": request.pregunta_id,
            "transcription": request.transcription,
            "analysis": analysis_data
        }
        
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump(full_data, f, ensure_ascii=False, indent=4)
            
    except Exception as e:
        print(f"Advertencia: No se pudo guardar el archivo JSON de an√°lisis. {e}")
        
    # 5. Respuesta
    return AnalysisResponse(**analysis_data)

